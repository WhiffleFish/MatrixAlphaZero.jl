using Distributed
p = addprocs(3; exeflags="--project=$(Base.active_project())")

@everywhere begin
    # Pkg.activate("experiments")
    using MatrixAlphaZero
    using MarkovGames
    const AZ = MatrixAlphaZero
    using ExperimentTools
    const Tools = ExperimentTools
    using SDAGames.SNRGame
    using SDAGames.SatelliteDynamics
    using Flux
    using Distributions
    using POMDPTools
    using POMDPs
    using ProgressMeter
    # using Plots
    using DelimitedFiles
    using LaTeXStrings
    # default(grid=false, framestyle=:box, fontfamily="Computer Modern", label="")
end

@everywhere begin
    game = SNRSDAGame()
    oracle = Flux.loadmodel!(AZ.load_oracle(@__DIR__), @modeldir("oracle0100.jld2"))
    oracle0 = Flux.loadmodel!(AZ.load_oracle(@__DIR__), @modeldir("oracle0100.jld2"))
    planner = AlphaZeroPlanner(game, oracle, max_iter=1000, c=10.0)

    s0 = SNRGame.SDAState(
        sOSCtoCART([
            R_EARTH .+ 3e6,
            0.0,
            0.0,
            0.0,
            0.0,
            deg2rad(160)
        ]),
        sOSCtoCART([
            R_EARTH .+ 5e6,
            0.0,
            0.0,
            0.0,
            0.0,
            deg2rad(160)
        ]),
        game.epc0,
        false
    )
end


br_vals = @showprogress pmap(readdir(@modeldir; join=true)) do modelpath
    _planner = deepcopy(planner)
    Flux.loadmodel!(_planner, modelpath)
    π1 = Tools.policy1_from_oracle(_planner.oracle)
    π2 = Tools.policy2_from_oracle(_planner.oracle)
    brv1, brv2 = Tools.approx_br_values_both_st(game, oracle0, π1, π2, s0)
end

brvs1, brvs2 = getindex.(br_vals, 1), getindex.(br_vals, 2)

plot(
    plot(brvs1, lw=5), # Player-1 value when Player-2 plays BR to π₁ (min over a₂, expect over π₁)
    plot(-brvs2, lw=5) # Player-2 value when Player-1 plays BR to π₂ (max over a₁, expect over π₂)
)

plot(AZ.state_value(oracle, game, s0) .- brvs1, lw=5, xlabel="Training Iteration", ylabel="Observer Exploitability")

plot(-AZ.state_value(oracle, game, s0) .+ brvs2, lw=5, xlabel="Training Iteration", ylabel="Observer Exploitability")

brv_path = joinpath(@__DIR__, "brv2")
writedlm(joinpath(brv_path, "brv1.csv"), brvs1, ',')
writedlm(joinpath(brv_path, "brv2.csv"), brvs2, ',')

##

stuff = @showprogress pmap(1:100) do i
    Tools.search_eval(planner, MCTSParams(planner), game, s0)
end

brv_path = joinpath(@__DIR__, "brv3")
isdir(brv_path) || mkdir(brv_path)
iter = stuff[1][:iter]
mcts_brv1 = mapreduce(hcat, stuff) do brv_i
    brv_i.brv1
end
mcts_brv2 = mapreduce(hcat, stuff) do brv_i
    brv_i.brv2
end
mcts_v = reduce(hcat, getfield.(stuff, :v))


writedlm(joinpath(brv_path, "mcts_iter.csv"), iter, ',')
writedlm(joinpath(brv_path, "mcts_brv1.csv"), mcts_brv1, ',')
writedlm(joinpath(brv_path, "mcts_brv2.csv"), mcts_brv2, ',')
writedlm(joinpath(brv_path, "mcts_v.csv"), mcts_v, ',')



μ1 = vec(mean(mcts_brv1, dims=2))
σ1 = vec(std(mcts_brv1, dims=2))
μ2 = vec(mean(mcts_brv2, dims=2))
σ2 = vec(std(mcts_brv2, dims=2))

p_brv1 = plot(iter, μ1, ribbon=σ1, c=1, lw=2, xlabel="Search Iterations", ylabel=L"U^1(\pi^1, \textbf{BR}(\pi^1))")
p_brv2 = plot(iter, -μ2, ribbon=σ2, c=2, lw=2, xlabel="Search Iterations", ylabel=L"U^2(\textbf{BR}(\pi^2), \pi^2)")

μtot = vec(mean(-mcts_brv1 .+ mcts_brv2, dims=2))
σtot = vec(std(-mcts_brv1 .+ mcts_brv2, dims=2))

p_tot = plot(iter, 0.5 * μtot, ribbon=0.5 * σtot,
    xlabel = "Search Iterations",
    ylabel = "Exploitability",
    fillcolor=:lightgray,
    lw=5,
    fillalpha=0.5,
    c=3
    # size=(500, 500),
    # size=(500Plots.mm, 500Plots.mm)
)

plot(
    plot(p_brv1, p_brv2, layout=(1,2)),
    p_tot,
    layout = (2,1),
    suptitle = "Matrix MCTS Performance",
    size = (500, 700)
)
savefig(@figdir("matrix-mcts-performance2.pdf"))

plot(
    plot(p_brv1, p_brv2, layout=(2,1)),
    p_tot,
    layout = (1,2),
    suptitle = "Matrix MCTS Performance",
    size = (900, 500),
    left_margin = 4Plots.mm,
    bottom_margin = 4Plots.mm
)
savefig(@figdir("matrix-mcts-performance-horizontal2.pdf"))

###
iter = readdlm(joinpath(brv_path, "mcts_iter.csv"),  ',')
mcts_brv1 = readdlm(joinpath(brv_path, "mcts_brv1.csv"),  ',')
mcts_brv2 = readdlm(joinpath(brv_path, "mcts_brv2.csv"),  ',')
mcts_v = readdlm(joinpath(brv_path, "mcts_v.csv"), ',')


##
brv1 = readdlm(joinpath(@__DIR__, "brv2", "brv1.csv"), ',') |> vec
brv2 = readdlm(joinpath(@__DIR__, "brv2", "brv2.csv"), ',') |> vec
oracle = Flux.loadmodel!(AZ.load_oracle(@__DIR__), @modeldir("oracle0100.jld2"))
v0 = AZ.state_value(oracle, game, s0)

plot(
    plot(
        plot(brv1, c=1, lw=2, ylabel = L"U^1(\pi^1, \textbf{BR}(\pi^1))"),
        plot(-brv2, c=2, lw=2, xlabel="Training Iteration", ylabel = L"U^2(\textbf{BR}(\pi^2), \pi^2)"),
        layout=(2,1)
    ),
    plot(
        0.5 .* (-brv1 .+ brv2),
        xlabel = "Training Iteration", 
        ylabel = "Exploitability",
        lw = 2,
        c = 3
    ),
    layout=(1,2),
    suptitle = "Policy Network Performance"
)
savefig(@figdir("policy-network-performance.pdf"))


